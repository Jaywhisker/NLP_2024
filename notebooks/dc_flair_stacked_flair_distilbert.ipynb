{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ning\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from flair.data import Corpus, Sentence\n",
    "from flair.datasets import ClassificationCorpus\n",
    "from flair.embeddings import (\n",
    "    WordEmbeddings,\n",
    "    FlairEmbeddings,\n",
    "    DocumentRNNEmbeddings,\n",
    "    TransformerWordEmbeddings,\n",
    "    StackedEmbeddings,\n",
    ")\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.training_utils import EvaluationMetric\n",
    "from flair.visual.training_curves import Plotter\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import flair\n",
    "flair.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {flair.device}\")\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1+cu124\n",
      "CUDA Available: True\n",
      "CUDA Version: 12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA Version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-03 18:21:18,430 Reading data from data\\flair_data\n",
      "2024-12-03 18:21:18,430 Train: data\\flair_data\\train.txt\n",
      "2024-12-03 18:21:18,430 Dev: data\\flair_data\\dev.txt\n",
      "2024-12-03 18:21:18,430 Test: data\\flair_data\\test.txt\n",
      "2024-12-03 18:21:18,956 Initialized corpus data\\flair_data (label type name is 'sentiment')\n",
      "Number of training sentences: 22500\n",
      "Number of validation sentences: 2500\n",
      "Number of test sentences: 25000\n"
     ]
    }
   ],
   "source": [
    "# Ensure the output directory exists\n",
    "flair_data_folder = \"data/flair_data\"\n",
    "os.makedirs(flair_data_folder, exist_ok=True)\n",
    "\n",
    "# Define the folder where the data is located\n",
    "corpus_folder = Path(flair_data_folder)\n",
    "\n",
    "# Create the corpus\n",
    "corpus = ClassificationCorpus(\n",
    "    corpus_folder,\n",
    "    train_file='train.txt',\n",
    "    dev_file='dev.txt',\n",
    "    test_file='test.txt',\n",
    "    label_type='sentiment'\n",
    ")\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Number of training sentences: {len(corpus.train)}\")\n",
    "print(f\"Number of validation sentences: {len(corpus.dev)}\")\n",
    "print(f\"Number of test sentences: {len(corpus.test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-03 18:21:18,960 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "22500it [00:42, 527.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-03 18:22:01,633 Dictionary created for label 'sentiment' with 2 values: POS (seen 11298 times), NEG (seen 11202 times)\n",
      "Dictionary with 2 tags: POS, NEG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_dict = corpus.make_label_dictionary(label_type='sentiment')\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Set Up Stacked Embeddings\n",
    "flair_forward_embedding = FlairEmbeddings('news-forward')\n",
    "flair_backward_embedding = FlairEmbeddings('news-backward')\n",
    "transformer_word_embeddings = TransformerWordEmbeddings('distilbert-base-uncased')\n",
    "\n",
    "# List of embeddings\n",
    "embeddings = [\n",
    "    flair_forward_embedding,\n",
    "    flair_backward_embedding,\n",
    "    transformer_word_embeddings,\n",
    "]\n",
    "\n",
    "# Create document embeddings from word embeddings\n",
    "document_embeddings = DocumentRNNEmbeddings(\n",
    "    embeddings=embeddings,\n",
    "    hidden_size=256,\n",
    "    reproject_words=True,\n",
    "    reproject_words_dimension=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TextClassifier(\n",
    "    document_embeddings,\n",
    "    label_dictionary=label_dict,\n",
    "    label_type='sentiment'\n",
    ").to(flair.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef3aff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "def evaluate_model(classifier, test_dataset):\n",
    "    \"\"\"\n",
    "    Evaluate a Flair classifier on a given test dataset, with verification and debugging steps.\n",
    "\n",
    "    Args:\n",
    "        classifier (TextClassifier): The trained Flair classifier.\n",
    "        test_dataset (Dataset): The test dataset.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Label mapping\n",
    "    label_mapping = {\"NEG\": 0, \"POS\": 1}\n",
    "\n",
    "    # Iterate over the test dataset with tqdm progress bar\n",
    "    for sentence in tqdm.tqdm(test_dataset, desc=\"Evaluating\", leave=True):\n",
    "        sentence.to(flair.device)\n",
    "\n",
    "        # Get true label\n",
    "        true_label = sentence.get_label(\"sentiment\").value\n",
    "        true_labels.append(true_label)\n",
    "\n",
    "        # Get predicted label\n",
    "        classifier.predict(sentence)\n",
    "        predicted_label = sentence.labels[0].value\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "    # Verify label consistency\n",
    "    print(\"True Labels Sample:\", true_labels[:5])\n",
    "    print(\"Predicted Labels Sample:\", predicted_labels[:5])\n",
    "    print(\"True Label Distribution:\", Counter(true_labels))\n",
    "    print(\"Predicted Label Distribution:\", Counter(predicted_labels))\n",
    "\n",
    "    # Map labels to numeric values for sklearn\n",
    "    try:\n",
    "        true_labels_mapped = [label_mapping[label] for label in true_labels]\n",
    "        predicted_labels_mapped = [label_mapping[label] for label in predicted_labels]\n",
    "    except KeyError as e:\n",
    "        print(f\"Label mapping error: {e}. Ensure all labels are in {label_mapping}.\")\n",
    "        return {}\n",
    "\n",
    "    # Verify mapped labels\n",
    "    print(\"Mapped True Labels Sample:\", true_labels_mapped[:5])\n",
    "    print(\"Mapped Predicted Labels Sample:\", predicted_labels_mapped[:5])\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels_mapped, predicted_labels_mapped)\n",
    "    precision = precision_score(true_labels_mapped, predicted_labels_mapped, pos_label=1, zero_division=0)\n",
    "    recall = recall_score(true_labels_mapped, predicted_labels_mapped, pos_label=1, zero_division=0)\n",
    "    f1 = f1_score(true_labels_mapped, predicted_labels_mapped, pos_label=1, zero_division=0)\n",
    "\n",
    "    # Full classification report\n",
    "    classification_rep = classification_report(\n",
    "        true_labels_mapped,\n",
    "        predicted_labels_mapped,\n",
    "        target_names=[\"NEG\", \"POS\"]  # Match target names with label_mapping\n",
    "    )\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_rep)\n",
    "\n",
    "    # Return metrics as a dictionary\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"classification_report\": classification_rep,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b50412d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-03 18:22:03,826 Reading data from data\\flair_data\n",
      "2024-12-03 18:22:03,827 Train: data\\flair_data\\train_small.txt\n",
      "2024-12-03 18:22:03,827 Dev: data\\flair_data\\dev_small.txt\n",
      "2024-12-03 18:22:03,827 Test: data\\flair_data\\test_small.txt\n",
      "2024-12-03 18:22:03,831 Initialized corpus data/flair_data (label type name is 'sentiment')\n",
      "2024-12-03 18:22:03,833 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-03 18:22:03,834 Model: \"TextClassifier(\n",
      "  (embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.05, inplace=False)\n",
      "          (encoder): Embedding(300, 100)\n",
      "          (rnn): LSTM(100, 2048)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.05, inplace=False)\n",
      "          (encoder): Embedding(300, 100)\n",
      "          (rnn): LSTM(100, 2048)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): TransformerWordEmbeddings(\n",
      "        (model): DistilBertModel(\n",
      "          (embeddings): Embeddings(\n",
      "            (word_embeddings): Embedding(30523, 768, padding_idx=0)\n",
      "            (position_embeddings): Embedding(512, 768)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (transformer): Transformer(\n",
      "            (layer): ModuleList(\n",
      "              (0-5): 6 x TransformerBlock(\n",
      "                (attention): DistilBertSdpaAttention(\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                )\n",
      "                (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (ffn): FFN(\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (activation): GELUActivation()\n",
      "                )\n",
      "                (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=4864, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 256, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2024-12-03 18:22:03,834 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-03 18:22:03,834 Corpus: 22500 train + 2500 dev + 25000 test sentences\n",
      "2024-12-03 18:22:03,835 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-03 18:22:03,835 Train:  22500 sentences\n",
      "2024-12-03 18:22:03,835         (train_with_dev=False, train_with_test=False)\n",
      "2024-12-03 18:22:03,835 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-03 18:22:03,836 Training Params:\n",
      "2024-12-03 18:22:03,836  - learning_rate: \"5e-05\" \n",
      "2024-12-03 18:22:03,836  - mini_batch_size: \"16\"\n",
      "2024-12-03 18:22:03,838  - max_epochs: \"10\"\n",
      "2024-12-03 18:22:03,838  - shuffle: \"True\"\n",
      "2024-12-03 18:22:03,838 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-03 18:22:03,838 Plugins:\n",
      "2024-12-03 18:22:03,839  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2024-12-03 18:22:03,839 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-03 18:22:03,840 Final evaluation on model from best epoch (best-model.pt)\n",
      "2024-12-03 18:22:03,840  - metric: \"('micro avg', 'f1-score')\"\n",
      "2024-12-03 18:22:03,840 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-03 18:22:03,840 Computation:\n",
      "2024-12-03 18:22:03,841  - compute on device: cuda\n",
      "2024-12-03 18:22:03,841  - embedding storage: gpu\n",
      "2024-12-03 18:22:03,841 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-03 18:22:03,842 Model training base path: \"flair_model\"\n",
      "2024-12-03 18:22:03,842 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-03 18:22:03,842 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ning\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flair\\trainers\\trainer.py:499: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp and flair.device.type != \"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-03 18:40:44,374 epoch 1 - iter 140/1407 - loss 0.70971192 - time (sec): 1120.53 - samples/sec: 2.00 - lr: 0.000005 - momentum: 0.000000\n",
      "2024-12-03 18:59:58,059 epoch 1 - iter 280/1407 - loss 0.67125986 - time (sec): 2274.22 - samples/sec: 1.97 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-12-03 19:24:28,877 epoch 1 - iter 420/1407 - loss 0.56417752 - time (sec): 3745.03 - samples/sec: 1.79 - lr: 0.000015 - momentum: 0.000000\n",
      "2024-12-03 19:47:53,884 epoch 1 - iter 560/1407 - loss 0.50285825 - time (sec): 5150.04 - samples/sec: 1.74 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-12-03 20:10:01,058 epoch 1 - iter 700/1407 - loss 0.46016501 - time (sec): 6477.22 - samples/sec: 1.73 - lr: 0.000025 - momentum: 0.000000\n",
      "2024-12-03 20:31:58,632 epoch 1 - iter 840/1407 - loss 0.43516031 - time (sec): 7794.79 - samples/sec: 1.72 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-12-03 20:50:19,360 epoch 1 - iter 980/1407 - loss 0.41024027 - time (sec): 8895.52 - samples/sec: 1.76 - lr: 0.000035 - momentum: 0.000000\n",
      "2024-12-03 21:15:21,221 epoch 1 - iter 1120/1407 - loss 0.39463625 - time (sec): 10397.38 - samples/sec: 1.72 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-12-03 21:39:08,763 epoch 1 - iter 1260/1407 - loss 0.38263858 - time (sec): 11824.92 - samples/sec: 1.70 - lr: 0.000045 - momentum: 0.000000\n",
      "2024-12-03 22:04:28,044 epoch 1 - iter 1400/1407 - loss 0.37147035 - time (sec): 13344.20 - samples/sec: 1.68 - lr: 0.000050 - momentum: 0.000000\n",
      "2024-12-03 22:05:56,215 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-03 22:05:56,215 EPOCH 1 done: loss 0.3708 - lr: 0.000050\n",
      "2024-12-03 22:05:56,216 Saving model at current epoch since 'save_model_each_k_epochs=1' was set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [32:51<00:00, 12.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-03 22:38:48,419 DEV : loss 0.33744463324546814 - f1-score (micro avg)  0.9004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-03 22:38:53,718 saving best model\n",
      "2024-12-03 22:38:54,220 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-03 23:18:19,202 epoch 2 - iter 140/1407 - loss 0.22787478 - time (sec): 2364.98 - samples/sec: 0.95 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-12-04 00:00:46,566 epoch 2 - iter 280/1407 - loss 0.23892554 - time (sec): 4912.34 - samples/sec: 0.91 - lr: 0.000049 - momentum: 0.000000\n",
      "2024-12-04 00:39:02,959 epoch 2 - iter 420/1407 - loss 0.23037537 - time (sec): 7208.74 - samples/sec: 0.93 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-12-04 01:17:47,070 epoch 2 - iter 560/1407 - loss 0.23122157 - time (sec): 9532.85 - samples/sec: 0.94 - lr: 0.000048 - momentum: 0.000000\n",
      "2024-12-04 01:55:51,751 epoch 2 - iter 700/1407 - loss 0.22478482 - time (sec): 11817.53 - samples/sec: 0.95 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-12-04 02:34:20,982 epoch 2 - iter 840/1407 - loss 0.22478380 - time (sec): 14126.76 - samples/sec: 0.95 - lr: 0.000047 - momentum: 0.000000\n",
      "2024-12-04 03:12:00,720 epoch 2 - iter 980/1407 - loss 0.22572339 - time (sec): 16386.50 - samples/sec: 0.96 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-12-04 03:50:18,419 epoch 2 - iter 1120/1407 - loss 0.22215317 - time (sec): 18684.20 - samples/sec: 0.96 - lr: 0.000046 - momentum: 0.000000\n",
      "2024-12-04 04:27:59,241 epoch 2 - iter 1260/1407 - loss 0.22292693 - time (sec): 20945.02 - samples/sec: 0.96 - lr: 0.000045 - momentum: 0.000000\n",
      "2024-12-04 05:05:31,965 epoch 2 - iter 1400/1407 - loss 0.22147344 - time (sec): 23197.74 - samples/sec: 0.97 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-12-04 05:07:12,204 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-04 05:07:12,204 EPOCH 2 done: loss 0.2214 - lr: 0.000044\n",
      "2024-12-04 05:07:12,205 Saving model at current epoch since 'save_model_each_k_epochs=1' was set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [31:20<00:00, 11.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-04 05:38:32,980 DEV : loss 0.3276882469654083 - f1-score (micro avg)  0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-04 05:38:38,004 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-04 06:16:55,606 epoch 3 - iter 140/1407 - loss 0.13563384 - time (sec): 2297.60 - samples/sec: 0.97 - lr: 0.000044 - momentum: 0.000000\n",
      "2024-12-04 06:54:15,681 epoch 3 - iter 280/1407 - loss 0.12973217 - time (sec): 4537.68 - samples/sec: 0.99 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-12-04 07:32:25,388 epoch 3 - iter 420/1407 - loss 0.13003129 - time (sec): 6827.38 - samples/sec: 0.98 - lr: 0.000043 - momentum: 0.000000\n",
      "2024-12-04 08:11:09,769 epoch 3 - iter 560/1407 - loss 0.13230037 - time (sec): 9151.76 - samples/sec: 0.98 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-12-04 08:48:24,438 epoch 3 - iter 700/1407 - loss 0.13160721 - time (sec): 11386.43 - samples/sec: 0.98 - lr: 0.000042 - momentum: 0.000000\n",
      "2024-12-04 09:27:19,313 epoch 3 - iter 840/1407 - loss 0.13585726 - time (sec): 13721.31 - samples/sec: 0.98 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-12-04 10:03:31,138 epoch 3 - iter 980/1407 - loss 0.13407195 - time (sec): 15893.13 - samples/sec: 0.99 - lr: 0.000041 - momentum: 0.000000\n",
      "2024-12-04 10:41:06,127 epoch 3 - iter 1120/1407 - loss 0.13632947 - time (sec): 18148.12 - samples/sec: 0.99 - lr: 0.000040 - momentum: 0.000000\n",
      "2024-12-04 11:18:59,344 epoch 3 - iter 1260/1407 - loss 0.13635027 - time (sec): 20421.34 - samples/sec: 0.99 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-12-04 11:58:54,163 epoch 3 - iter 1400/1407 - loss 0.13817310 - time (sec): 22816.16 - samples/sec: 0.98 - lr: 0.000039 - momentum: 0.000000\n",
      "2024-12-04 12:00:21,249 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-04 12:00:21,250 EPOCH 3 done: loss 0.1382 - lr: 0.000039\n",
      "2024-12-04 12:00:21,250 Saving model at current epoch since 'save_model_each_k_epochs=1' was set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [31:10<00:00, 11.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-04 12:31:32,399 DEV : loss 0.38121363520622253 - f1-score (micro avg)  0.9108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-04 12:31:37,663 saving best model\n",
      "2024-12-04 12:31:38,148 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-04 13:09:24,014 epoch 4 - iter 140/1407 - loss 0.04894524 - time (sec): 2265.86 - samples/sec: 0.99 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-12-04 13:47:56,385 epoch 4 - iter 280/1407 - loss 0.07164522 - time (sec): 4578.24 - samples/sec: 0.98 - lr: 0.000038 - momentum: 0.000000\n",
      "2024-12-04 14:24:18,448 epoch 4 - iter 420/1407 - loss 0.06864954 - time (sec): 6760.30 - samples/sec: 0.99 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-12-04 15:00:58,254 epoch 4 - iter 560/1407 - loss 0.06719500 - time (sec): 8960.11 - samples/sec: 1.00 - lr: 0.000037 - momentum: 0.000000\n",
      "2024-12-04 15:37:56,492 epoch 4 - iter 700/1407 - loss 0.07707795 - time (sec): 11178.34 - samples/sec: 1.00 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-12-04 16:15:11,274 epoch 4 - iter 840/1407 - loss 0.07700706 - time (sec): 13413.13 - samples/sec: 1.00 - lr: 0.000036 - momentum: 0.000000\n",
      "2024-12-04 16:51:02,995 epoch 4 - iter 980/1407 - loss 0.07686697 - time (sec): 15564.85 - samples/sec: 1.01 - lr: 0.000035 - momentum: 0.000000\n",
      "2024-12-04 17:30:16,258 epoch 4 - iter 1120/1407 - loss 0.07667805 - time (sec): 17918.11 - samples/sec: 1.00 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-12-04 18:11:56,994 epoch 4 - iter 1260/1407 - loss 0.07771452 - time (sec): 20418.85 - samples/sec: 0.99 - lr: 0.000034 - momentum: 0.000000\n",
      "2024-12-04 18:50:33,488 epoch 4 - iter 1400/1407 - loss 0.07956380 - time (sec): 22735.34 - samples/sec: 0.99 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-12-04 18:51:56,414 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-04 18:51:56,414 EPOCH 4 done: loss 0.0806 - lr: 0.000033\n",
      "2024-12-04 18:51:56,415 Saving model at current epoch since 'save_model_each_k_epochs=1' was set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [40:22<00:00, 15.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-04 19:32:19,614 DEV : loss 0.38885292410850525 - f1-score (micro avg)  0.9188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-04 19:32:24,763 saving best model\n",
      "2024-12-04 19:32:25,221 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-04 20:09:56,737 epoch 5 - iter 140/1407 - loss 0.03200944 - time (sec): 2251.51 - samples/sec: 0.99 - lr: 0.000033 - momentum: 0.000000\n",
      "2024-12-04 20:45:38,339 epoch 5 - iter 280/1407 - loss 0.03304739 - time (sec): 4393.12 - samples/sec: 1.02 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-12-04 21:24:58,768 epoch 5 - iter 420/1407 - loss 0.03928664 - time (sec): 6753.55 - samples/sec: 1.00 - lr: 0.000032 - momentum: 0.000000\n",
      "2024-12-04 22:02:40,559 epoch 5 - iter 560/1407 - loss 0.03937346 - time (sec): 9015.34 - samples/sec: 0.99 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-12-04 22:42:42,431 epoch 5 - iter 700/1407 - loss 0.03751128 - time (sec): 11417.21 - samples/sec: 0.98 - lr: 0.000031 - momentum: 0.000000\n",
      "2024-12-04 23:21:33,758 epoch 5 - iter 840/1407 - loss 0.03679222 - time (sec): 13748.54 - samples/sec: 0.98 - lr: 0.000030 - momentum: 0.000000\n",
      "2024-12-05 00:00:02,400 epoch 5 - iter 980/1407 - loss 0.03881241 - time (sec): 16057.18 - samples/sec: 0.98 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-12-05 00:40:19,004 epoch 5 - iter 1120/1407 - loss 0.03942522 - time (sec): 18473.78 - samples/sec: 0.97 - lr: 0.000029 - momentum: 0.000000\n",
      "2024-12-05 01:17:04,977 epoch 5 - iter 1260/1407 - loss 0.03831028 - time (sec): 20679.75 - samples/sec: 0.97 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-12-05 01:54:55,563 epoch 5 - iter 1400/1407 - loss 0.03938419 - time (sec): 22950.34 - samples/sec: 0.98 - lr: 0.000028 - momentum: 0.000000\n",
      "2024-12-05 01:56:49,465 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-05 01:56:49,465 EPOCH 5 done: loss 0.0397 - lr: 0.000028\n",
      "2024-12-05 01:56:49,465 Saving model at current epoch since 'save_model_each_k_epochs=1' was set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [42:59<00:00, 16.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-05 02:39:48,939 DEV : loss 0.5793805718421936 - f1-score (micro avg)  0.9212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-05 02:39:53,879 saving best model\n",
      "2024-12-05 02:39:54,237 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-05 03:18:13,642 epoch 6 - iter 140/1407 - loss 0.01637261 - time (sec): 2299.40 - samples/sec: 0.97 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-12-05 03:54:51,096 epoch 6 - iter 280/1407 - loss 0.02102738 - time (sec): 4496.86 - samples/sec: 1.00 - lr: 0.000027 - momentum: 0.000000\n",
      "2024-12-05 04:32:12,583 epoch 6 - iter 420/1407 - loss 0.02083186 - time (sec): 6738.34 - samples/sec: 1.00 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-12-05 05:12:01,800 epoch 6 - iter 560/1407 - loss 0.02621299 - time (sec): 9127.56 - samples/sec: 0.98 - lr: 0.000026 - momentum: 0.000000\n",
      "2024-12-05 05:49:36,067 epoch 6 - iter 700/1407 - loss 0.02547396 - time (sec): 11381.83 - samples/sec: 0.98 - lr: 0.000025 - momentum: 0.000000\n",
      "2024-12-05 06:26:54,281 epoch 6 - iter 840/1407 - loss 0.02490445 - time (sec): 13620.04 - samples/sec: 0.99 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-12-05 07:04:35,395 epoch 6 - iter 980/1407 - loss 0.02440862 - time (sec): 15881.16 - samples/sec: 0.99 - lr: 0.000024 - momentum: 0.000000\n",
      "2024-12-05 07:42:28,835 epoch 6 - iter 1120/1407 - loss 0.02448596 - time (sec): 18154.60 - samples/sec: 0.99 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-12-05 08:19:33,119 epoch 6 - iter 1260/1407 - loss 0.02579171 - time (sec): 20378.88 - samples/sec: 0.99 - lr: 0.000023 - momentum: 0.000000\n",
      "2024-12-05 08:54:54,549 epoch 6 - iter 1400/1407 - loss 0.02687584 - time (sec): 22500.31 - samples/sec: 1.00 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-12-05 08:56:38,855 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-05 08:56:38,856 EPOCH 6 done: loss 0.0270 - lr: 0.000022\n",
      "2024-12-05 08:56:38,856 Saving model at current epoch since 'save_model_each_k_epochs=1' was set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [30:46<00:00, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-05 09:27:26,003 DEV : loss 0.5343671441078186 - f1-score (micro avg)  0.9204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-05 09:27:30,956 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-05 10:04:23,623 epoch 7 - iter 140/1407 - loss 0.00798728 - time (sec): 2212.67 - samples/sec: 1.01 - lr: 0.000022 - momentum: 0.000000\n",
      "2024-12-05 10:45:13,219 epoch 7 - iter 280/1407 - loss 0.01166894 - time (sec): 4662.26 - samples/sec: 0.96 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-12-05 11:25:32,882 epoch 7 - iter 420/1407 - loss 0.01188168 - time (sec): 7081.93 - samples/sec: 0.95 - lr: 0.000021 - momentum: 0.000000\n",
      "2024-12-05 12:03:54,519 epoch 7 - iter 560/1407 - loss 0.01574838 - time (sec): 9383.56 - samples/sec: 0.95 - lr: 0.000020 - momentum: 0.000000\n",
      "2024-12-05 12:41:44,609 epoch 7 - iter 700/1407 - loss 0.01550765 - time (sec): 11653.65 - samples/sec: 0.96 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-12-05 13:18:54,804 epoch 7 - iter 840/1407 - loss 0.01515138 - time (sec): 13883.85 - samples/sec: 0.97 - lr: 0.000019 - momentum: 0.000000\n",
      "2024-12-05 13:58:01,285 epoch 7 - iter 980/1407 - loss 0.01439362 - time (sec): 16230.33 - samples/sec: 0.97 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-12-05 14:35:36,866 epoch 7 - iter 1120/1407 - loss 0.01484568 - time (sec): 18485.91 - samples/sec: 0.97 - lr: 0.000018 - momentum: 0.000000\n",
      "2024-12-05 15:13:40,350 epoch 7 - iter 1260/1407 - loss 0.01421420 - time (sec): 20769.39 - samples/sec: 0.97 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-12-05 15:50:07,493 epoch 7 - iter 1400/1407 - loss 0.01356428 - time (sec): 22956.54 - samples/sec: 0.98 - lr: 0.000017 - momentum: 0.000000\n",
      "2024-12-05 15:51:56,466 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-05 15:51:56,466 EPOCH 7 done: loss 0.0135 - lr: 0.000017\n",
      "2024-12-05 15:51:56,466 Saving model at current epoch since 'save_model_each_k_epochs=1' was set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [32:42<00:00, 12.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-05 16:24:40,210 DEV : loss 0.6759727001190186 - f1-score (micro avg)  0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-05 16:24:45,144 saving best model\n",
      "2024-12-05 16:24:45,477 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-05 17:02:50,626 epoch 8 - iter 140/1407 - loss 0.01056803 - time (sec): 2285.15 - samples/sec: 0.98 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-12-05 17:39:25,083 epoch 8 - iter 280/1407 - loss 0.01011907 - time (sec): 4479.61 - samples/sec: 1.00 - lr: 0.000016 - momentum: 0.000000\n",
      "2024-12-05 18:16:31,577 epoch 8 - iter 420/1407 - loss 0.00857263 - time (sec): 6706.10 - samples/sec: 1.00 - lr: 0.000015 - momentum: 0.000000\n",
      "2024-12-05 18:54:38,109 epoch 8 - iter 560/1407 - loss 0.00732613 - time (sec): 8992.63 - samples/sec: 1.00 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-12-05 19:32:45,190 epoch 8 - iter 700/1407 - loss 0.00690599 - time (sec): 11279.71 - samples/sec: 0.99 - lr: 0.000014 - momentum: 0.000000\n",
      "2024-12-05 20:10:20,674 epoch 8 - iter 840/1407 - loss 0.00694750 - time (sec): 13535.20 - samples/sec: 0.99 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-12-05 20:50:13,265 epoch 8 - iter 980/1407 - loss 0.00850119 - time (sec): 15927.79 - samples/sec: 0.98 - lr: 0.000013 - momentum: 0.000000\n",
      "2024-12-05 21:27:57,540 epoch 8 - iter 1120/1407 - loss 0.00825721 - time (sec): 18192.06 - samples/sec: 0.99 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-12-05 22:05:50,408 epoch 8 - iter 1260/1407 - loss 0.00812946 - time (sec): 20464.93 - samples/sec: 0.99 - lr: 0.000012 - momentum: 0.000000\n",
      "2024-12-05 22:45:12,675 epoch 8 - iter 1400/1407 - loss 0.00925126 - time (sec): 22827.20 - samples/sec: 0.98 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-12-05 22:46:46,397 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-05 22:46:46,398 EPOCH 8 done: loss 0.0093 - lr: 0.000011\n",
      "2024-12-05 22:46:46,398 Saving model at current epoch since 'save_model_each_k_epochs=1' was set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [34:18<00:00, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-05 23:21:05,849 DEV : loss 0.6266456842422485 - f1-score (micro avg)  0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-05 23:21:10,845 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-05 23:56:09,919 epoch 9 - iter 140/1407 - loss 0.00649136 - time (sec): 2099.07 - samples/sec: 1.07 - lr: 0.000011 - momentum: 0.000000\n",
      "2024-12-06 00:34:52,437 epoch 9 - iter 280/1407 - loss 0.00593049 - time (sec): 4421.59 - samples/sec: 1.01 - lr: 0.000010 - momentum: 0.000000\n",
      "2024-12-06 01:13:15,165 epoch 9 - iter 420/1407 - loss 0.00410749 - time (sec): 6724.32 - samples/sec: 1.00 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-12-06 01:50:44,860 epoch 9 - iter 560/1407 - loss 0.00425486 - time (sec): 8974.01 - samples/sec: 1.00 - lr: 0.000009 - momentum: 0.000000\n",
      "2024-12-06 02:29:25,597 epoch 9 - iter 700/1407 - loss 0.00448478 - time (sec): 11294.75 - samples/sec: 0.99 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-12-06 03:07:45,766 epoch 9 - iter 840/1407 - loss 0.00592652 - time (sec): 13594.92 - samples/sec: 0.99 - lr: 0.000008 - momentum: 0.000000\n",
      "2024-12-06 03:45:56,846 epoch 9 - iter 980/1407 - loss 0.00580298 - time (sec): 15886.00 - samples/sec: 0.99 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-12-06 04:22:41,791 epoch 9 - iter 1120/1407 - loss 0.00507993 - time (sec): 18090.94 - samples/sec: 0.99 - lr: 0.000007 - momentum: 0.000000\n",
      "2024-12-06 04:59:04,721 epoch 9 - iter 1260/1407 - loss 0.00531315 - time (sec): 20273.88 - samples/sec: 0.99 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-12-06 05:37:46,620 epoch 9 - iter 1400/1407 - loss 0.00478309 - time (sec): 22595.77 - samples/sec: 0.99 - lr: 0.000006 - momentum: 0.000000\n",
      "2024-12-06 05:39:11,767 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-06 05:39:11,768 EPOCH 9 done: loss 0.0048 - lr: 0.000006\n",
      "2024-12-06 05:39:11,768 Saving model at current epoch since 'save_model_each_k_epochs=1' was set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [29:34<00:00, 11.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 06:08:46,795 DEV : loss 0.7458382844924927 - f1-score (micro avg)  0.9288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 06:08:51,775 saving best model\n",
      "2024-12-06 06:08:52,138 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-06 06:48:11,293 epoch 10 - iter 140/1407 - loss 0.00001014 - time (sec): 2359.16 - samples/sec: 0.95 - lr: 0.000005 - momentum: 0.000000\n",
      "2024-12-06 07:25:09,065 epoch 10 - iter 280/1407 - loss 0.00102093 - time (sec): 4576.93 - samples/sec: 0.98 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-12-06 08:03:36,095 epoch 10 - iter 420/1407 - loss 0.00164725 - time (sec): 6883.96 - samples/sec: 0.98 - lr: 0.000004 - momentum: 0.000000\n",
      "2024-12-06 08:41:08,240 epoch 10 - iter 560/1407 - loss 0.00123949 - time (sec): 9136.10 - samples/sec: 0.98 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-12-06 09:20:01,200 epoch 10 - iter 700/1407 - loss 0.00185058 - time (sec): 11469.06 - samples/sec: 0.98 - lr: 0.000003 - momentum: 0.000000\n",
      "2024-12-06 09:58:41,615 epoch 10 - iter 840/1407 - loss 0.00155128 - time (sec): 13789.48 - samples/sec: 0.97 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-12-06 10:37:49,769 epoch 10 - iter 980/1407 - loss 0.00209492 - time (sec): 16137.63 - samples/sec: 0.97 - lr: 0.000002 - momentum: 0.000000\n",
      "2024-12-06 11:14:09,691 epoch 10 - iter 1120/1407 - loss 0.00241442 - time (sec): 18317.55 - samples/sec: 0.98 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-12-06 11:52:50,042 epoch 10 - iter 1260/1407 - loss 0.00214808 - time (sec): 20637.90 - samples/sec: 0.98 - lr: 0.000001 - momentum: 0.000000\n",
      "2024-12-06 12:30:00,634 epoch 10 - iter 1400/1407 - loss 0.00228690 - time (sec): 22868.50 - samples/sec: 0.98 - lr: 0.000000 - momentum: 0.000000\n",
      "2024-12-06 12:31:51,416 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-06 12:31:51,416 EPOCH 10 done: loss 0.0023 - lr: 0.000000\n",
      "2024-12-06 12:31:51,416 Saving model at current epoch since 'save_model_each_k_epochs=1' was set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [30:07<00:00, 11.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 13:01:59,773 DEV : loss 0.7704070210456848 - f1-score (micro avg)  0.9284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 13:02:05,071 ----------------------------------------------------------------------------------------------------\n",
      "2024-12-06 13:02:05,072 Loading model from best epoch ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [4:18:48<00:00,  9.94s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 17:20:55,301 \n",
      "Results:\n",
      "- F-score (micro) 0.929\n",
      "- F-score (macro) 0.929\n",
      "- Accuracy 0.929\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         POS     0.9208    0.9387    0.9297     12500\n",
      "         NEG     0.9375    0.9193    0.9283     12500\n",
      "\n",
      "    accuracy                         0.9290     25000\n",
      "   macro avg     0.9292    0.9290    0.9290     25000\n",
      "weighted avg     0.9292    0.9290    0.9290     25000\n",
      "\n",
      "2024-12-06 17:20:55,302 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.929}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "import logging\n",
    "\n",
    "\n",
    "# Test on small dataset\n",
    "small_data_folder = \"data/flair_data\"\n",
    "small_corpus = ClassificationCorpus(small_data_folder, \n",
    "                                    train_file=\"train_small.txt\",  \n",
    "                                    dev_file='dev_small.txt', \n",
    "                                    test_file='test_small.txt',\n",
    "                                    label_type=\"sentiment\")\n",
    "\n",
    "\n",
    "# Set the logging level to INFO\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "#Fine-tune the model\n",
    "trainer.fine_tune(\n",
    "    base_path='flair_model',             # Directory to save the model and logs\n",
    "    learning_rate=5e-5,                  # Learning rate for fine-tuning\n",
    "    mini_batch_size=16,                   # Smaller batch size for transformers\n",
    "    max_epochs=10,                        # Number of epochs\n",
    "    embeddings_storage_mode='gpu',     \n",
    "    optimizer=AdamW,                     # Optimizer suited for transformers\n",
    "    save_final_model=True,               # Save the final model\n",
    "    save_model_each_k_epochs=1,          # Save model checkpoint every epoch\n",
    "    create_file_logs=True,               # Save logs to a file\n",
    "    create_loss_file=True,               # Save loss values to a file\n",
    "    use_final_model_for_eval=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 25000/25000 [3:56:31<00:00,  1.76it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Labels Sample: ['NEG', 'NEG', 'NEG', 'NEG', 'NEG']\n",
      "Predicted Labels Sample: ['POS', 'NEG', 'NEG', 'NEG', 'NEG']\n",
      "True Label Distribution: Counter({'NEG': 12500, 'POS': 12500})\n",
      "Predicted Label Distribution: Counter({'POS': 12743, 'NEG': 12257})\n",
      "Mapped True Labels Sample: [0, 0, 0, 0, 0]\n",
      "Mapped Predicted Labels Sample: [1, 0, 0, 0, 0]\n",
      "\n",
      "Accuracy: 0.9290\n",
      "Precision: 0.9208\n",
      "Recall: 0.9387\n",
      "F1 Score: 0.9297\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.94      0.92      0.93     12500\n",
      "         POS       0.92      0.94      0.93     12500\n",
      "\n",
      "    accuracy                           0.93     25000\n",
      "   macro avg       0.93      0.93      0.93     25000\n",
      "weighted avg       0.93      0.93      0.93     25000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the saved model\n",
    "saved_model_path = \"flair_model/best-model.pt\"  # Update this if the path or filename is different\n",
    "\n",
    "# Load the trained model\n",
    "classifier = TextClassifier.load(saved_model_path).to(flair.device)\n",
    "\n",
    "# Evaluate the model\n",
    "results = evaluate_model(classifier, corpus.test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
